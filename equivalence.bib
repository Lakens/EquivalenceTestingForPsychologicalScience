
@article{Dienes2014,
  timestamp = {2017-10-03T09:22:49Z},
  title = {Using {{Bayes}} to Get the Most out of Non-Significant Results},
  volume = {5},
  doi = {10.3389/fpsyg.2014.00781},
  abstract = {No scientific conclusion follows automatically from a statistically non-significant result, yet people routinely use non-significant results to guide conclusions about the status of theories (or the effectiveness of practices). To know whether a non-significant result counts against a theory, or if it just indicates data insensitivity, researchers must use one of: power, intervals (such as confidence or credibility intervals), or else an indicator of the relative evidence for one theory over another, such as a Bayes factor. I argue Bayes factors allow theory to be linked to data in a way that overcomes the weaknesses of the other approaches. Specifically, Bayes factors use the data themselves to determine their sensitivity in distinguishing theories (unlike power), and they make use of those aspects of a theory's predictions that are often easiest to specify (unlike power and intervals, which require specifying the minimal interesting value in order to address theory). Bayes factors provide a coherent approach to determining whether non-significant results support a null hypothesis over a theory, or whether the data are just insensitive. They allow accepting and rejecting the null hypothesis to be put on an equal footing. Concrete examples are provided to indicate the range of application of a simple online Bayes calculator, which reveal both the strengths and weaknesses of Bayes factors.},
  urldate = {2016-06-22},
  journal = {Quantitative Psychology and Measurement},
  author = {Dienes, Zoltan},
  year = {2014},
  keywords = {Bayes factor,confidence interval,highest density region,null hypothesis,power,significance testing,Statistical inference},
  pages = {781}
}

@article{Platt1964,
  timestamp = {2017-10-02T14:38:09Z},
  title = {Strong Inference},
  volume = {146},
  number = {3642},
  urldate = {2015-12-30},
  journal = {science},
  author = {Platt, John R.},
  year = {1964},
  pages = {347--353}
}

@article{Lenth2007,
  timestamp = {2017-10-01T20:11:36Z},
  title = {Post Hoc Power: Tables and Commentary},
  shorttitle = {Post Hoc Power},
  urldate = {2017-09-30},
  journal = {Iowa City: Department of Statistics and Actuarial Science, University of Iowa},
  author = {Lenth, Russell V.},
  year = {2007}
}

@article{Lenth2001,
  timestamp = {2017-10-01T20:11:36Z},
  title = {Some Practical Guidelines for Effective Sample Size Determination},
  volume = {55},
  number = {3},
  urldate = {2017-09-30},
  journal = {The American Statistician},
  author = {Lenth, Russell V.},
  year = {2001},
  pages = {187--193}
}

@article{Button2015,
  timestamp = {2017-10-01T20:11:36Z},
  title = {Minimal Clinically Important Difference on the {{Beck Depression Inventory}} - {{II}} According to the Patient's Perspective},
  volume = {45},
  issn = {0033-2917, 1469-8978},
  doi = {10.1017/S0033291715001270},
  abstract = {Background
The Beck Depression Inventory, 2nd edition (BDI-II) is widely used in research on depression. However, the minimal clinically important difference (MCID) is unknown. MCID can be estimated in several ways. Here we take a patient-centred approach, anchoring the change on the BDI-II to the patient's global report of improvement.

Method
 We used data collected (n = 1039) from three randomized controlled trials for the management of depression. Improvement on a `global rating of change' question was compared with changes in BDI-II scores using general linear modelling to explore baseline dependency, assessing whether MCID is best measured in absolute terms (i.e. difference) or as percent reduction in scores from baseline (i.e. ratio), and receiver operator characteristics (ROC) to estimate MCID according to the optimal threshold above which individuals report feeling `better'.

Results
Improvement in BDI-II scores associated with reporting feeling `better' depended on initial depression severity, and statistical modelling indicated that MCID is best measured on a ratio scale as a percentage reduction of score. We estimated a MCID of a 17.5\% reduction in scores from baseline from ROC analyses. The corresponding estimate for individuals with longer duration depression who had not responded to antidepressants was higher at 32\%.

Conclusions
MCID on the BDI-II is dependent on baseline severity, is best measured on a ratio scale, and the MCID for treatment-resistant depression is larger than that for more typical depression. This has important implications for clinical trials and practice.},
  number = {15},
  urldate = {2017-10-01},
  journal = {Psychological Medicine},
  author = {Button, K. S. and Kounali, D. and Thomas, L. and Wiles, N. J. and Peters, T. J. and Welton, N. J. and Ades, A. E. and Lewis, G.},
  month = nov,
  year = {2015},
  keywords = {2nd edition (BDI-II),Beck Depression Inventory,depression,minimal clinically important difference,outcome assessment,primary care},
  pages = {3269--3279}
}

@book{Machin2008,
  timestamp = {2017-10-01T20:11:36Z},
  address = {Chichester, West Sussex, UK ; Hoboken, NJ},
  edition = {3rd ed},
  title = {Sample Size Tables for Clinical Studies},
  isbn = {978-1-4051-4650-0},
  lccn = {R853.C55 S36 2008},
  publisher = {{Wiley-Blackwell}},
  editor = {Machin, David},
  year = {2008},
  keywords = {Clinical trials,Clinical Trials as Topic,Research Design,Sample Size,Statistical methods,Statistics as Topic},
  annote = {Basic design considerations -- Distributions and confidence intervals -- Comparing two independent groups for binary data -- Comparing two independent groups for ordered categorical data -- Comparing two independent groups for continuous data -- Cluster designs, repeated measures data and more than two groups -- Comparing paired groups for binary, ordered categorical and continuous outcomes -- Comparing survival curves -- Equivalence -- Confidence intervals -- Post-marketing surveillance -- The correlation coefficient -- Reference intervals and receiver operating curves -- Observer agreement studies -- Dose finding studies -- Phase II trials -- Sample size software (SSS)}
}

@article{Hoenig2001,
  timestamp = {2017-10-01T20:11:36Z},
  title = {The Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis},
  volume = {55},
  shorttitle = {The Abuse of Power},
  number = {1},
  urldate = {2017-09-30},
  journal = {The American Statistician},
  author = {Hoenig, John M. and Heisey, Dennis M.},
  year = {2001},
  pages = {19--24}
}

@article{Burriss2015,
  timestamp = {2017-10-01T20:11:36Z},
  title = {Changes in {{Women}}'s {{Facial Skin Color}} over the {{Ovulatory Cycle}} Are {{Not Detectable}} by the {{Human Visual System}}},
  volume = {10},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0130093},
  abstract = {Human ovulation is not advertised, as it is in several primate species, by conspicuous sexual swellings. However, there is increasing evidence that the attractiveness of women's body odor, voice, and facial appearance peak during the fertile phase of their ovulatory cycle. Cycle effects on facial attractiveness may be underpinned by changes in facial skin color, but it is not clear if skin color varies cyclically in humans or if any changes are detectable. To test these questions we photographed women daily for at least one cycle. Changes in facial skin redness and luminance were then quantified by mapping the digital images to human long, medium, and shortwave visual receptors. We find cyclic variation in skin redness, but not luminance. Redness decreases rapidly after menstrual onset, increases in the days before ovulation, and remains high through the luteal phase. However, we also show that this variation is unlikely to be detectable by the human visual system. We conclude that changes in skin color are not responsible for the effects of the ovulatory cycle on women's attractiveness.},
  number = {7},
  urldate = {2017-10-01},
  journal = {PLOS ONE},
  author = {Burriss, Robert P. and Troscianko, Jolyon and Lovell, P. George and Fulford, Anthony J. C. and Stevens, Martin and Quigley, Rachael and Payne, Jenny and Saxton, Tamsin K. and Rowland, Hannah M.},
  month = jul,
  year = {2015},
  keywords = {Cameras,Color vision,Estradiol,Estrogens,Face,Luminance,Ovulation,Visual system},
  pages = {e0130093}
}

@book{Julious2010,
  timestamp = {2017-10-01T20:11:36Z},
  address = {Boca Raton},
  title = {Sample Sizes for Clinical Trials},
  isbn = {978-1-58488-739-3},
  lccn = {R853.C55 J85 2010},
  publisher = {{CRC Press/Taylor \& Francis}},
  author = {Julious, Steven A.},
  year = {2010},
  note = {OCLC: ocn288983232},
  keywords = {methods,Clinical trials,Clinical Trials as Topic,Sample Size,Statistical methods,Sampling (Statistics)},
  annote = {Seven key steps to cook up a sample size -- Sample sizes for parallel group superiority trials with normal data -- Sample size calculations for superiority cross-over trials with normal data -- Sample size calculations for equivalence clinical trials with normal data -- Sample size calculations for non-inferiority clinical trials with normal data -- Sample size calculations for bioequivalence trials -- Sample size calculations for precision clinical trials with normal data -- Sample size calculations for parallel group superiority clinical trials with binary data -- Sample size calculations for superiority cross-over clinical trials with binary data -- Sample size calculations for non-inferiority trials with binary data -- Sample size calculations for equivalence trials with binary data -- Sample size calculations for precision trials with binary data -- Sample size calculations for clinical trials with ordinal data -- Sample size calculations for clinical trials with survival data}
}

@article{Schuirmann1987,
  timestamp = {2017-10-01T20:11:10Z},
  title = {A Comparison of the Two One-Sided Tests Procedure and the Power Approach for Assessing the Equivalence of Average Bioavailability},
  volume = {15},
  number = {6},
  urldate = {2016-07-22},
  journal = {Journal of pharmacokinetics and biopharmaceutics},
  author = {Schuirmann, Donald J.},
  year = {1987},
  pages = {657--680}
}

@article{Bauer1996,
  timestamp = {2017-10-01T20:11:10Z},
  title = {A Unifying Approach for Confidence Intervals and Testing of Equivalence and Difference},
  volume = {83},
  number = {4},
  urldate = {2016-08-03},
  journal = {Biometrika},
  author = {Bauer, Peter and Kieser, Meinhard},
  year = {1996},
  pages = {934--937}
}

@article{Meyners2012,
  timestamp = {2017-10-01T20:11:10Z},
  title = {Equivalence Tests \textendash{} {{A}} Review},
  volume = {26},
  issn = {09503293},
  doi = {10.1016/j.foodqual.2012.05.003},
  language = {en},
  number = {2},
  urldate = {2016-08-06},
  journal = {Food Quality and Preference},
  author = {Meyners, Michael},
  month = dec,
  year = {2012},
  pages = {231--245}
}

@article{Mara2012,
  timestamp = {2017-10-01T20:11:10Z},
  title = {Paired-{{Samples Tests}} of {{Equivalence}}},
  volume = {41},
  issn = {0361-0918},
  doi = {10.1080/03610918.2011.626545},
  abstract = {Equivalence tests are used when the objective is to find that two or more groups are nearly equivalent on some outcome, such that any difference is inconsequential. Equivalence tests are available for several research designs, however, paired-samples equivalence tests that are accessible and relevant to the research performed by psychologists have been understudied. This study evaluated parametric and nonparametric two one-sided paired-samples equivalence tests and a standardized paired-samples equivalence test developed by Wellek (2003). The two one-sided procedures had better Type I error control and greater power than Wellek's test, with the nonparametric procedure having increased power with non normal distributions.},
  number = {10},
  urldate = {2016-08-31},
  journal = {Communications in Statistics - Simulation and Computation},
  author = {Mara, Constance A. and Cribbie, Robert A.},
  month = nov,
  year = {2012},
  pages = {1928--1943}
}

@book{Liu2008,
  timestamp = {2017-10-01T20:11:10Z},
  series = {Chapman \& Hall/CRC Biostatistics Series},
  title = {Design and {{Analysis}} of {{Bioavailability}} and {{Bioequivalence Studies}}, {{Third Edition}}},
  volume = {3},
  isbn = {978-1-58488-668-6 978-1-4200-1167-8},
  language = {en},
  urldate = {2016-11-24},
  publisher = {{Chapman and Hall/CRC}},
  author = {Liu, Jen-pei and Chow, Shein-Chung},
  month = oct,
  year = {2008}
}

@article{Senn1993,
  timestamp = {2017-10-01T20:11:10Z},
  title = {Inherent Difficulties with Active Control Equivalence Studies},
  volume = {12},
  number = {24},
  urldate = {2016-11-26},
  journal = {Statistics in medicine},
  author = {Senn, Stephen},
  year = {1993},
  pages = {2367--2375}
}

@article{Chen2000,
  timestamp = {2017-10-01T20:11:10Z},
  title = {Tests for {{Equivalence}} or {{Noninferiority}} between {{Two Proportions}}},
  volume = {34},
  issn = {0092-8615},
  doi = {10.1177/009286150003400225},
  abstract = {Bioequivalence between two treatments or two drugs is often assessed by comparing the two proportions (success rate or eradication rate) of binomial outcomes when the conventional pharmacokinetic parameters are inadequate for the assessment. Setting the equivalence limits can be based on one of the three measures: difference, ratio, or odds ratio between the two binomial probabilities. This paper reviews the existing asymptotic test statistics for comparing two independent binomial probabilities in terms of the three measures in the context of equivalence or noninferiority testing. The actual type I error and power of the asymptotic tests are evaluated by enumerating the exact probabilities in the rejection region. The results show that to establish an equivalence between two treatments with an equivalence limit of 20\% in difference, a sample size of at least 50 per treatment is needed. When the sample size is sufficient, the actual type I error rate is close to the nominal level (slightly above the nominal level in several cases) for a test in terms of difference for equivalence limits, and it tends to exceed the nominal level for tests in terms of ratio or odds ratio.},
  language = {en},
  number = {2},
  urldate = {2017-10-01},
  journal = {Drug Information Journal},
  author = {Chen, James J. and Tsong, Yi and Kang, Seung-Ho},
  month = apr,
  year = {2000},
  pages = {569--578}
}

@book{Wellek2010,
  timestamp = {2017-10-01T20:11:10Z},
  address = {Boca Raton},
  edition = {2nd ed},
  title = {Testing Statistical Hypotheses of Equivalence and Noninferiority},
  isbn = {978-1-4398-0818-4},
  lccn = {QA277 .W46 2010},
  publisher = {{CRC Press}},
  author = {Wellek, Stefan},
  year = {2010},
  keywords = {Statistical hypothesis testing},
  annote = {"A Chapman \& Hall book."}
}

@article{Hauck1984,
  timestamp = {2017-10-01T20:11:10Z},
  title = {A New Statistical Procedure for Testing Equivalence in Two-Group Comparative Bioavailability Trials},
  volume = {12},
  issn = {0090-466X},
  doi = {10.1007/BF01063612},
  abstract = {The clinical problem of testing for equivalence in comparative bioavailability trials is restated in terms of the proper statistical hypotheses. A simple t-test procedure for these hypotheses has been devloped that is more powerful than the methods based on usual (shortest) and symmetric confidence intervals. In this note, this new procedure is explained and an example is given, including the method for sample size determination.},
  language = {en},
  number = {1},
  urldate = {2016-07-27},
  journal = {Journal of Pharmacokinetics and Biopharmaceutics},
  author = {Hauck, Dr Walter W. and Anderson, Sharon},
  month = feb,
  year = {1984},
  keywords = {bioavailability,Biochemistry; general,bioequivalence,Biomedical Engineering,hypothesis tests,Pharmacology/Toxicology,Pharmacy,sample size determination,Veterinary Medicine},
  pages = {83--91}
}

@article{Seaman1998,
  timestamp = {2017-10-01T20:11:10Z},
  title = {Equivalence Confidence Intervals for Two-Group Comparisons of Means.},
  volume = {3},
  copyright = {\textcopyright{} American Psychological Association 1998},
  issn = {1082-989X},
  doi = {http://dx.doi.org.dianus.libr.tue.nl/10.1037/1082-989X.3.4.403},
  abstract = {Methods for determining whether 2 means are practically equivalent are discussed. Existing equivalency-testing procedures are reviewed and compared. An equivalence confidence interval is proposed and compared with the traditional confidence interval for a mean difference. The use of this new interval is described for both confirmatory and exploratory research and is shown to fit within the context of good-enough methods. Adaptations and extensions of the interval are proposed. (PsycINFO Database Record (c) 2013 APA, all rights reserved)(journal abstract)},
  language = {English},
  number = {4},
  urldate = {2016-07-27},
  journal = {Psychological Methods},
  author = {Seaman, Michael A. and Serlin, Ronald C.},
  month = dec,
  year = {1998},
  keywords = {Confidence Limits (Statistics) (major),Mean (major),Statistical Analysis (major)},
  pages = {403--411}
}

@article{Lakens2017a,
  timestamp = {2017-11-09T20:17:10Z},
  title = {Equivalence {{Tests}}: {{A Practical Primer}} for t {{Tests}}, {{Correlations}}, and {{Meta}}-{{Analyses}}},
  volume = {8},
  issn = {1948-5506},
  shorttitle = {Equivalence {{Tests}}},
  doi = {10.1177/1948550617697177},
  abstract = {Scientists should be able to provide support for the absence of a meaningful effect. Currently, researchers often incorrectly conclude an effect is absent based a nonsignificant result. A widely recommended approach within a frequentist framework is to test for equivalence. In equivalence tests, such as the two one-sided tests (TOST) procedure discussed in this article, an upper and lower equivalence bound is specified based on the smallest effect size of interest. The TOST procedure can be used to statistically reject the presence of effects large enough to be considered worthwhile. This practical primer with accompanying spreadsheet and R package enables psychologists to easily perform equivalence tests (and power analyses) by setting equivalence bounds based on standardized effect sizes and provides recommendations to prespecify equivalence bounds. Extending your statistical tool kit with equivalence tests is an easy way to improve your statistical and theoretical inferences.},
  language = {en},
  number = {4},
  urldate = {2017-07-08},
  journal = {Social Psychological and Personality Science},
  author = {Lakens, Dani{\"e}l},
  month = may,
  year = {2017},
  pages = {355--362}
}

@article{Tryon2001,
  timestamp = {2017-10-01T20:11:10Z},
  title = {Evaluating Statistical Difference, Equivalence, and Indeterminacy Using Inferential Confidence Intervals: An Integrated Alternative Method of Conducting Null Hypothesis Statistical Tests.},
  volume = {6},
  shorttitle = {Evaluating Statistical Difference, Equivalence, and Indeterminacy Using Inferential Confidence Intervals},
  number = {4},
  urldate = {2017-07-29},
  journal = {Psychological methods},
  author = {Tryon, Warren W.},
  year = {2001},
  pages = {371}
}

@article{Tryon2008,
  timestamp = {2017-10-01T20:11:10Z},
  title = {An Inferential Confidence Interval Method of Establishing Statistical Equivalence That Corrects {{Tryon}}'s (2001) Reduction Factor.},
  volume = {13},
  number = {3},
  urldate = {2017-07-29},
  journal = {Psychological methods},
  author = {Tryon, Warren W. and Lewis, Charles},
  year = {2008},
  pages = {272}
}

@article{Silva2008,
  timestamp = {2017-10-01T20:11:10Z},
  title = {Methods for {{Equivalence}} and {{Noninferiority Testing}}},
  volume = {15},
  issn = {1083-8791},
  doi = {10.1016/j.bbmt.2008.10.004},
  abstract = {Classical hypothesis testing focuses on testing whether treatments have differential effects on outcome. However, sometimes clinicians may be more interested in determining whether treatments are equivalent or whether one has noninferior outcomes. We review the hypotheses for these noninferiority and equivalence research questions, consider power and sample size issues, and discuss how to perform such a test for both binary and survival outcomes. The methods are illustrated on 2 recent studies in hematopoietic cell transplantation.},
  number = {1 Suppl},
  urldate = {2017-09-11},
  journal = {Biology of blood and marrow transplantation : journal of the American Society for Blood and Marrow Transplantation},
  author = {da Silva, Gisela Tunes and Logan, Brent R. and Klein, John P.},
  month = jan,
  year = {2008},
  pages = {120--127},
  pmid = {19147090},
  pmcid = {PMC2701110}
}

@book{Chow2007,
  timestamp = {2017-10-01T20:10:19Z},
  address = {Boca Raton},
  edition = {2 edition},
  title = {Sample {{Size Calculations}} in {{Clinical Research}}, {{Second Edition}}},
  isbn = {978-1-58488-982-3},
  abstract = {Focusing on an integral part of pharmaceutical development, Sample Size Calculations in Clinical Research, Second Edition presents statistical procedures for performing sample size calculations during various phases of clinical research and development. It provides sample size formulas and procedures for testing equality, noninferiority/superiority, and equivalence.    A comprehensive and unified presentation of statistical concepts and practical applications, this book highlights the interactions between clinicians and biostatisticians, includes a well-balanced summary of current and emerging clinical issues, and explores recently developed statistical methodologies for sample size calculation. Whenever possible, each chapter provides a brief history or background, regulatory requirements, statistical designs and methods for data analysis, real-world examples, future research developments, and related references.    One of the few books to systematically summarize clinical research procedures, this edition contains new chapters that focus on three key areas of this field. Incorporating the material of this book in your work will help ensure the validity and, ultimately, the success of your clinical studies.},
  language = {English},
  publisher = {{Chapman and Hall/CRC}},
  author = {Chow, Shein-Chung and Wang, Hansheng and Shao, Jun},
  month = aug,
  year = {2007}
}

@article{Dienes2017,
  timestamp = {2017-10-04T07:46:49Z},
  title = {Four Reasons to Prefer {{Bayesian}} Analyses over Significance Testing},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1266-z},
  abstract = {Inference using significance testing and Bayes factors is compared and contrasted in five case studies based on real research. The first study illustrates that the methods will often agree, both in motivating researchers to conclude that H1 is supported better than H0, and the other way round, that H0 is better supported than H1. The next four, however, show that the methods will also often disagree. In these cases, the aim of the paper will be to motivate the sensible evidential conclusion, and then see which approach matches those intuitions. Specifically, it is shown that a high-powered non-significant result is consistent with no evidence for H0 over H1 worth mentioning, which a Bayes factor can show, and, conversely, that a low-powered non-significant result is consistent with substantial evidence for H0 over H1, again indicated by Bayesian analyses. The fourth study illustrates that a high-powered significant result may not amount to any evidence for H1 over H0, matching the Bayesian conclusion. Finally, the fifth study illustrates that different theories can be evidentially supported to different degrees by the same data; a fact that P-values cannot reflect but Bayes factors can. It is argued that appropriate conclusions match the Bayesian inferences, but not those based on significance testing, where they disagree.},
  language = {en},
  urldate = {2017-10-04},
  journal = {Psychonomic Bulletin \& Review},
  author = {Dienes, Zoltan and Mclatchie, Neil},
  month = mar,
  year = {2017},
  pages = {1--12}
}

@book{Murphy2014,
  timestamp = {2017-10-10T15:08:59Z},
  title = {Statistical {{Power Analysis}}: {{A Simple}} and {{General Model}} for {{Traditional}} and {{Modern Hypothesis Tests}}, {{Fourth Edition}}},
  isbn = {978-1-317-68057-4},
  shorttitle = {Statistical {{Power Analysis}}},
  abstract = {Noted for its accessible approach, this text applies the latest approaches of power analysis to both null hypothesis and minimum-effect testing using the same basic unified model. Through the use of a few simple procedures and examples, the authors show readers with little expertise in statistical analysis how to obtain the values needed to carry out the power analysis for their research. Illustrations of how these analyses work and how they can be used to choose the appropriate criterion for defining statistically significant outcomes are sprinkled throughout. The book presents a simple and general model for statistical power analysis based on the F statistic and reviews how to determine: the sample size needed to achieve desired levels of power; the level of power needed in a study; the size of effect that can be reliably detected by a study; and sensible criteria for statistical significance. The book helps readers design studies, diagnose existing studies, and understand why hypothesis tests come out out the way they do.  The fourth edition features: -New Boxed Material sections provide examples of power analysis in action and discuss unique issues that arise as a result of applying power analyses in different designs. -Many more worked examples help readers apply the concepts presented. -Expanded coverage of power analysis for multifactor analysis of variance (ANOVA) to show readers how to analyze up to four factors with repeated measures on any or all of the factors. -Re-designed and expanded web based One Stop F Calculator software and data sets that allow users to perform all of the book's analyses and conduct significance tests, power analyses, and assessments of N and alpha needed for traditional and minimum-effects tests. -Easy to apply formulas for approximating the number of subjects required to reach adequate levels of power in a wide range of studies.  Intended as a supplement for graduate/advanced undergraduate courses in research methods or experimental design, intermediate, advanced, or multivariate statistics, statistics II, or psychometrics, taught in psychology, education, business, and other social and health sciences, researchers also appreciate the book`s applied approach.},
  language = {en},
  publisher = {{Routledge}},
  author = {Murphy, Kevin R. and Myors, Brett and Wolach, Allen},
  month = may,
  year = {2014},
  note = {Google-Books-ID: tYgZBAAAQBAJ},
  keywords = {Business \& Economics / Statistics,Education / Statistics,Psychology / Research \& Methodology,Psychology / Statistics}
}

@article{Simonsohn2015,
  timestamp = {2017-11-09T14:20:20Z},
  title = {Small {{Telescopes Detectability}} and the {{Evaluation}} of {{Replication Results}}},
  volume = {26},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797614567341},
  abstract = {This article introduces a new approach for evaluating replication results. It combines effect-size estimation with hypothesis testing, assessing the extent to which the replication results are consistent with an effect size big enough to have been detectable in the original study. The approach is demonstrated by examining replications of three well-known findings. Its benefits include the following: (a) differentiating ``unsuccessful'' replication attempts (i.e., studies yielding p $>$ .05) that are too noisy from those that actively indicate the effect is undetectably different from zero, (b) ``protecting'' true findings from underpowered replications, and (c) arriving at intuitively compelling inferences in general and for the revisited replications in particular.},
  language = {en},
  number = {5},
  urldate = {2016-08-08},
  journal = {Psychological Science},
  author = {Simonsohn, Uri},
  month = may,
  year = {2015},
  keywords = {replication,open materials,hypothesis testing,statistical power},
  pages = {559--569},
  pmid = {25800521}
}

@article{Weber2012,
  timestamp = {2017-11-09T14:19:53Z},
  title = {Testing {{Equivalence}} in {{Communication Research}}: {{Theory}} and {{Application}}},
  volume = {6},
  issn = {1931-2458},
  shorttitle = {Testing {{Equivalence}} in {{Communication Research}}},
  doi = {10.1080/19312458.2012.703834},
  abstract = {Although equivalence testing is preferred when a researcher's goal is to support the null hypothesis (i.e., no substantial effect), equivalence tests are virtually unknown and unused in the communication field. This article provides the rationale for and theoretical background of equivalence testing and offers examples of equivalence tests for the independent and dependent groups t-test and tests of association using Pearson's coefficient or correlation. From a review of meta-analyses, we provide tables of commonly observed effect-sizes across subdisciplines and topic areas in communication and offer these as a guideline for choosing minimum substantial effects ($\Delta$) in equivalence testing when no other information source is available. To facilitate the adoption of equivalence tests in future research, we provide easy-to-use custom dialogs for SPSS which greatly simplify their computation and application.},
  number = {3},
  urldate = {2016-05-16},
  journal = {Communication Methods and Measures},
  author = {Weber, Ren{\'e} and Popova, Lucy},
  month = jul,
  year = {2012},
  pages = {190--213}
}

@article{Hemphill2003,
  timestamp = {2017-11-09T14:18:30Z},
  title = {Interpreting the Magnitudes of Correlation Coefficients.},
  author = {Hemphill, James F.},
  year = {2003}
}

@article{Maxwell2015,
  timestamp = {2017-11-09T14:18:13Z},
  title = {Is Psychology Suffering from a Replication Crisis? {{What}} Does ``Failure to Replicate'' Really Mean?},
  volume = {70},
  issn = {1935-990X, 0003-066X},
  shorttitle = {Is Psychology Suffering from a Replication Crisis?},
  doi = {10.1037/a0039400},
  language = {en},
  number = {6},
  urldate = {2016-08-08},
  journal = {American Psychologist},
  author = {Maxwell, Scott E. and Lau, Michael Y. and Howard, George S.},
  year = {2015},
  pages = {487--498}
}

@book{Cohen1988,
  timestamp = {2017-11-09T14:17:36Z},
  address = {Hillsdale, N.J},
  edition = {2nd ed},
  title = {Statistical Power Analysis for the Behavioral Sciences},
  isbn = {978-0-8058-0283-2},
  lccn = {HA29 .C66 1988},
  publisher = {{L. Erlbaum Associates}},
  author = {Cohen, Jacob},
  year = {1988},
  keywords = {Statistical methods,Probabilities,Social sciences,Statistical power analysis},
  annote = {Includes index}
}

@article{Norman2004,
  timestamp = {2017-11-09T14:17:21Z},
  title = {The Truly Remarkable Universality of Half a Standard Deviation: Confirmation through Another Look},
  volume = {4},
  shorttitle = {The Truly Remarkable Universality of Half a Standard Deviation},
  number = {5},
  journal = {Expert review of pharmacoeconomics \& outcomes research},
  author = {Norman, Geoffrey R. and Sloan, Jeff A. and Wyrwich, Kathleen W.},
  year = {2004},
  pages = {581--585}
}

@article{Lakens2017b,
  timestamp = {2017-11-09T20:17:12Z},
  title = {Justify {{Your Alpha}}: {{A Response}} to ``{{Redefine Statistical Significance}}''},
  shorttitle = {Justify {{Your Alpha}}},
  doi = {10.17605/OSF.IO/9S3Y6},
  abstract = {In response to recommendations to redefine statistical significance to p $\leq$ .005, we propose that researchers should transparently report and justify all choices they make when designing a study, including the alpha level.},
  urldate = {2017-10-27},
  journal = {PsyArXiv},
  author = {Lakens, Dani{\"e}l and Adolfi, Federico G. and Albers, Casper and Anvari, Farid and Apps, Matthew A. J. and Argamon, Shlomo Engelson and van Assen, Marcel A. L. M. and Baguley, Thom and Becker, Raymond and Benning, Stephen D. and Bradford, Daniel E. and Buchanan, Erin Michelle and Caldwell, Aaron and van Calster, Ben and Carlsson, Rickard and Chen, Sau-Chin and Chung, Bryan and Colling, Lincoln and Collins, Gary and Crook, Zander and Cross, Emily S. and Daniels, Sameera and Danielsson, Henrik and DeBruine, Lisa and Dunleavy, Daniel and Earp, Brian D. and Feist, Michele and Ferrell, Jason D. and Field, James G. and Fox, Nick and Friesen, Amanda and Gomes, Caio and Grange, James A. and Grieve, Andrew and Guggenberger, Robert and Harmelen, Anne-Laura Van and Hasselman, Fred and Hochard, Kevin D. and Hoffarth, Mark Romeo and Holmes, Nicholas Paul and Ingre, Michael and Isager, Peder and Isotalus, Hanna and Johansson, Christer and Juszczyk, Konrad and Kenny, David and Khalil, Ahmed Abdelrahim and Konat, Barbara and Lao, Junpeng and Larsen, Erik Gahner and Lodder, Gerine M. A. and Lukavsky, Jiri and Madan, Christopher and Manheim, David and Gonzalez-Marquez, Monica and Martin, Stephen R. and Martin, Andrea E. and Mayo, Deborah and McCarthy, Randy J. and McConway, Kevin and McFarland, Colin and Nilsonne, Gustav and Nio, Amanda Q. X. and de Oliveira, Cilene Lino and Parsons, Sam and Pfuhl, Gerit and Quinn, Kimberly and Sakon, John and Saribay, Selahattin Adil and Schneider, Iris and Selvaraju, Manojkumar and Sjoerds, Zsuzsika and Smith, Samuel and Smits, Tim and Spies, Jeffrey R. and Sreekumar, Vishnu and Steltenpohl, Crystal and Stenhouse, Neil and {\'S}wi\k{a}tkowski, Wojciech and Vadillo, Miguel A. and Williams, Matt and Williams, Samantha and Williams, Donald R. and de Xivry, Jean-Jacques Orban and Yarkoni, Tal and Ziano, Ignazio and Zwaan, Rolf},
  month = sep,
  year = {2017}
}

@article{Banerjee2012,
  timestamp = {2017-11-09T19:10:56Z},
  title = {Is {{It Light}} or {{Dark}}? {{Recalling Moral Behavior Changes Perception}} of {{Brightness}}},
  volume = {23},
  issn = {0956-7976, 1467-9280},
  shorttitle = {Is {{It Light}} or {{Dark}}?},
  doi = {10.1177/0956797611432497},
  language = {en},
  number = {4},
  urldate = {2017-11-09},
  journal = {Psychological Science},
  author = {Banerjee, Pronobesh and Chatterjee, Promothesh and Sinha, Jayati},
  month = apr,
  year = {2012},
  pages = {407--409}
}

@article{Brandt2014,
  timestamp = {2017-11-09T19:11:39Z},
  title = {Does {{Recalling Moral Behavior Change}} the {{Perception}} of {{Brightness}}?: {{A Replication}} and {{Meta}}-{{Analysis}} of {{Banerjee}}, {{Chatterjee}}, and {{Sinha}} (2012)},
  volume = {45},
  issn = {1864-9335, 2151-2590},
  shorttitle = {Does {{Recalling Moral Behavior Change}} the {{Perception}} of {{Brightness}}?},
  doi = {10.1027/1864-9335/a000191},
  language = {en},
  number = {3},
  urldate = {2017-11-09},
  journal = {Social Psychology},
  author = {Brandt, Mark J. and IJzerman, Hans and Blanken, Irene},
  month = may,
  year = {2014},
  pages = {246--252}
}

@article{Kahane2015,
  timestamp = {2017-11-09T19:14:05Z},
  title = {`{{Utilitarian}}' Judgments in Sacrificial Moral Dilemmas Do Not Reflect Impartial Concern for the Greater Good},
  volume = {134},
  issn = {00100277},
  doi = {10.1016/j.cognition.2014.10.005},
  language = {en},
  urldate = {2017-11-09},
  journal = {Cognition},
  author = {Kahane, Guy and Everett, Jim A.C. and Earp, Brian D. and Farias, Miguel and Savulescu, Julian},
  month = jan,
  year = {2015},
  pages = {193--209}
}

@article{Baguley2009,
  timestamp = {2017-11-09T19:15:13Z},
  title = {Standardized or Simple Effect Size: {{What}} Should Be Reported?},
  volume = {100},
  issn = {00071269},
  shorttitle = {Standardized or Simple Effect Size},
  doi = {10.1348/000712608X377117},
  language = {en},
  number = {3},
  urldate = {2017-11-09},
  journal = {British Journal of Psychology},
  author = {Baguley, Thom},
  month = aug,
  year = {2009},
  pages = {603--617}
}

@article{Brown2017,
  timestamp = {2017-11-09T19:17:12Z},
  title = {Preliminary {{Evidence}} for {{How}} the {{Behavioral Immune System Predicts Juror Decision}}-{{Making}}},
  issn = {2198-9885},
  doi = {10.1007/s40806-017-0102-z},
  language = {en},
  urldate = {2017-11-09},
  journal = {Evolutionary Psychological Science},
  author = {Brown, Mitch and Rodriguez, Dario N. and Gretak, Alyssa P. and Berry, Melissa A.},
  month = may,
  year = {2017}
}

@article{Piaggio2006,
  timestamp = {2017-11-09T19:18:28Z},
  title = {Reporting of {{Noninferiority}} and {{Equivalence Randomized Trials}}: {{An Extension}} of the {{CONSORT Statement}}},
  volume = {295},
  issn = {0098-7484},
  shorttitle = {Reporting of {{Noninferiority}} and {{Equivalence Randomized Trials}}},
  doi = {10.1001/jama.295.10.1152},
  language = {en},
  number = {10},
  urldate = {2017-11-09},
  journal = {JAMA},
  author = {Piaggio, Gilda and Elbourne, Diana R. and Altman, Douglas G. and Pocock, Stuart J. and Evans, Stephen J. W. and the CONSORT Group, for},
  month = mar,
  year = {2006},
  pages = {1152}
}

@article{Schumann2017,
  timestamp = {2017-11-09T19:22:09Z},
  title = {When Is Computer-Mediated Intergroup Contact Most Promising? {{Examining}} the Effect of out-Group Members' Anonymity on Prejudice},
  volume = {77},
  issn = {07475632},
  shorttitle = {When Is Computer-Mediated Intergroup Contact Most Promising?},
  doi = {10.1016/j.chb.2017.08.006},
  language = {en},
  urldate = {2017-11-09},
  journal = {Computers in Human Behavior},
  author = {Schumann, Sandy and Klein, Olivier and Douglas, Karen and Hewstone, Miles},
  month = dec,
  year = {2017},
  pages = {198--210}
}

@article{Shih1999,
  timestamp = {2017-11-09T19:22:56Z},
  title = {Stereotype {{Susceptibility}}: {{Identity Salience}} and {{Shifts}} in {{Quantitative Performance}}},
  volume = {10},
  issn = {0956-7976, 1467-9280},
  shorttitle = {Stereotype {{Susceptibility}}},
  doi = {10.1111/1467-9280.00111},
  language = {en},
  number = {1},
  urldate = {2017-11-09},
  journal = {Psychological Science},
  author = {Shih, Margaret and Pittinsky, Todd L. and Ambady, Nalini},
  month = jan,
  year = {1999},
  pages = {80--83}
}

@article{Williams2008,
  timestamp = {2017-11-09T19:23:51Z},
  title = {Experiencing {{Physical Warmth Promotes Interpersonal Warmth}}},
  volume = {322},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1162548},
  language = {en},
  number = {5901},
  urldate = {2017-11-09},
  journal = {Science},
  author = {Williams, L. E. and Bargh, J. A.},
  month = oct,
  year = {2008},
  pages = {606--607}
}

@article{Perugini2014,
  timestamp = {2017-11-09T19:24:34Z},
  title = {Safeguard {{Power}} as a {{Protection Against Imprecise Power Estimates}}},
  volume = {9},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691614528519},
  language = {en},
  number = {3},
  urldate = {2017-11-09},
  journal = {Perspectives on Psychological Science},
  author = {Perugini, Marco and Gallucci, Marcello and Costantini, Giulio},
  month = may,
  year = {2014},
  pages = {319--332}
}

@article{Hyde2008,
  timestamp = {2017-11-09T19:40:20Z},
  title = {Gender {{Similarities Characterize Math Performance}}},
  volume = {321},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1160364},
  language = {en},
  number = {5888},
  urldate = {2017-11-09},
  journal = {Science},
  author = {Hyde, J. S. and Lindberg, S. M. and Linn, M. C. and Ellis, A. B. and Williams, C. C.},
  month = jul,
  year = {2008},
  pages = {494--495}
}

@article{Lynott2014,
  timestamp = {2017-11-09T19:41:03Z},
  title = {Replication of ``{{Experiencing Physical Warmth Promotes Interpersonal Warmth}}'' by {{Williams}} and {{Bargh}} (2008)},
  volume = {45},
  issn = {1864-9335, 2151-2590},
  doi = {10.1027/1864-9335/a000187},
  language = {en},
  number = {3},
  urldate = {2017-11-09},
  journal = {Social Psychology},
  author = {Lynott, Dermot and Corker, Katherine S. and Wortman, Jessica and Connell, Louise and Donnellan, M. Brent and Lucas, Richard E. and O'Brien, Kerry},
  month = may,
  year = {2014},
  pages = {216--222}
}

@book{UnitedStates2016,
  timestamp = {2017-11-10T09:34:24Z},
  address = {Washington, DC},
  title = {The {{CIA}} World Factbook 2017},
  isbn = {978-1-5107-1288-1},
  language = {English},
  author = {{United States} and {Central Intelligence Agency}},
  year = {2016},
  note = {OCLC: 936533494}
}

@article{Kordsmeyer2017,
  timestamp = {2017-11-09T19:48:25Z},
  title = {The Association of Three Indicators of Developmental Instability with Mating Success in Humans},
  volume = {38},
  issn = {10905138},
  doi = {10.1016/j.evolhumbehav.2017.08.002},
  language = {en},
  number = {6},
  urldate = {2017-11-09},
  journal = {Evolution and Human Behavior},
  author = {Kordsmeyer, Tobias L. and Penke, Lars},
  month = nov,
  year = {2017},
  pages = {704--713}
}

@article{Moon2014,
  timestamp = {2017-11-09T19:49:11Z},
  title = {A {{Secondary Replication Attempt}} of {{Stereotype Susceptibility}} ({{Shih}}, {{Pittinsky}}, \& {{Ambady}}, 1999)},
  volume = {45},
  issn = {1864-9335, 2151-2590},
  doi = {10.1027/1864-9335/a000193},
  language = {en},
  number = {3},
  urldate = {2017-11-09},
  journal = {Social Psychology},
  author = {Moon, Alice and Roeder, Scott S.},
  month = may,
  year = {2014},
  pages = {199--201}
}


